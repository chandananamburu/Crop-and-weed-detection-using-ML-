# -*- coding: utf-8 -*-
"""Copy of Crop and Weed Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mjIGboXHJNYMql7CotN7vc15sz3LRQxx
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import os
from PIL import Image
import cv2

from google.colab import drive
drive.mount('/content/drive')

directory = "/content/drive/MyDrive/agri_data/data"
directory

"""Sample images along with labels
1.   Label 0 indicates that image is a sesame crop
2.   Label 1 indicates that image is a weed


"""

import os
import cv2
from google.colab.patches import cv2_imshow

# directory = 'path_to_your_directory'

# Get a list of image files
image_files = [filename for filename in os.listdir(directory) if filename.endswith(('.jpg', '.png', '.jpeg'))]

# Choose a sample image file
sample_image_file = image_files[4]
sample_image_path = os.path.join(directory, sample_image_file)

# Open the sample image using OpenCV
sample_image = cv2.imread(sample_image_path)

# Get the corresponding text file with labels
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)

# Read the labels from the text file
with open(sample_text_path, 'r') as text_file:
    labels = text_file.readlines()

print("Image:", sample_image_file)
print("Labels:", labels)

# Display the image using cv2_imshow
cv2_imshow(sample_image)

image_files = [filename for filename in os.listdir(directory) if filename.endswith(('.jpg', '.png', '.jpeg'))]
sample_image_file = image_files[4]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
  labels = text_file.readlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

sample_image_file = image_files[12]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
    labels = text_file.read().splitlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

sample_image_file = image_files[64]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
    labels = text_file.read().splitlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

sample_image_file = image_files[65]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
    labels = text_file.read().splitlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

sample_image_file = image_files[14]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
    labels = text_file.read().splitlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

sample_image_file = image_files[104]
sample_image_path = os.path.join(directory, sample_image_file)
sample_image = cv2.imread(sample_image_path)
sample_text_file = os.path.splitext(sample_image_file)[0] + ".txt"
sample_text_path = os.path.join(directory, sample_text_file)
with open(sample_text_path, 'r') as text_file:
    labels = text_file.read().splitlines()
print("Image: ", sample_image_file)
print("Labels: ", labels)
cv2_imshow(sample_image)

"""# **DATA PRE PROCESSING**"""

height = 512
width = 512 # fixing the image sizes
input_shape = (height,width,3)
input_shape

# Directories to save the separated images
crops = '/content/drive/MyDrive/agri_data/crops'
weeds = '/content/drive/MyDrive/agri_data/weeds'
crops

for filename in os.listdir(directory):
    if filename.endswith(".jpg") or filename.endswith(".png") or filename.endswith(".jpeg"):
        image_path = os.path.join(directory, filename)
        image = Image.open(image_path)

        text_filename = os.path.splitext(filename)[0] + ".txt"
        text_path = os.path.join(directory, text_filename)

        with open(text_path, 'r') as text_file:
            lines = text_file.read().splitlines()
        counter = 1
        for line in lines:
            values = line.split()
            label = int(values[0])
            x = float(values[1])
            y = float(values[2])
            width = float(values[3])
            height = float(values[4])

            if label == 0:
                category = "crop"
            elif label == 1:
                category = "weed"
            else:
                category = "unknown"

            left = int(x * input_shape[0])
            top = int(y * input_shape[1])
            right = int((x + width) * input_shape[0])
            bottom = int((y + height) * input_shape[1])

            crop_image = image.crop((left, top, right, bottom))

            save_filename = f"{os.path.splitext(filename)[0]}_{label}_{counter}.jpg"

            if category == "crop":
                save_path = os.path.join(crops, save_filename)
            else:
                save_path = os.path.join(weeds, save_filename)

            crop_image.save(save_path)
            counter += 1

"""## **Printing the images after seperating them**

## **1. Images of Crops**
"""

crops = '/content/drive/MyDrive/agri_data/TrainData/crops'
weeds = '/content/drive/MyDrive/agri_data/TrainData/weeds'

image_files = [filename for filename in os.listdir(crops) if filename.endswith(('.jpg', '.png', '.jpeg'))]
sample_image_file = image_files[0]
sample_image_path = os.path.join(crops, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

sample_image_file = image_files[190]
sample_image_path = os.path.join(crops, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

sample_image_file = image_files[30]
sample_image_path = os.path.join(crops, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

"""## 2. Images of weeds"""

image_files = [filename for filename in os.listdir(weeds) if filename.endswith(('.jpg', '.png', '.jpeg'))]
sample_image_file = image_files[0]
sample_image_path = os.path.join(weeds, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

sample_image_file = image_files[10]
sample_image_path = os.path.join(weeds, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

sample_image_file = image_files[80]
sample_image_path = os.path.join(weeds, sample_image_file)
sample_image = cv2.imread(sample_image_path)
print("Image: ", sample_image_file)
cv2_imshow(sample_image)

train_dir = "/content/drive/MyDrive/agri_data/TrainData"

import random
import shutil

labels = ['crops','weeds']
labels

import cv2
import numpy as np
import os

img_size=256
data=[]

def get_training_data(data_dir):
  tz=0
  for label in labels:
    path=os.path.join(data_dir,label)
    print(path)
    class_num=labels.index(label)
    print(class_num)
    for img in os.listdir(path):
      try:
        img_arr=cv2.imread(os.path.join(path,img),cv2.COLOR_BAYER_GB2RGB)
        resized_arr=cv2.resize(img_arr,(img_size,img_size))
        data.append([resized_arr,class_num])
      except Exception as e:
        print(e)
  return np.array(class_num)

  return np.array(data)
train=get_training_data("/content/drive/MyDrive/agri_data/TrainData")
data

lst = os.listdir('/content/drive/MyDrive/agri_data/TrainData/crops')
number_files = len(lst)
print(number_files)

lst = os.listdir('/content/drive/MyDrive/agri_data/TrainData/weeds')
number_files = len(lst)
print(number_files)

x = []
y = []
for i,j in data:
  x.append(i)
  y.append(j)
print(len(y))

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.20,random_state=42,shuffle=True)
print(len(xtrain))
print(len(xtest))
print(len(ytrain))
print(len(ytest))

xtrain = np.array(xtrain)
xtest = np.array(xtest)
print(xtrain.shape)
print(xtest.shape)

total_elements = np.prod(xtrain.shape)
new_shape_elements = 1657 * 196608
print("Total elements in original array:", total_elements)
print("Elements required for new shape:", new_shape_elements)

# Verify original shape and total elements
print("Original shape of xtrain:", xtrain.shape)
total_elements = np.prod(xtrain.shape)
print("Total elements in xtrain:", total_elements)

# Reshape the array correctly
if total_elements % (256 * 256 * 3) == 0:
    num_samples = total_elements // (256 * 256 * 3)
    xtrain1 = xtrain.reshape(num_samples, 256 * 256 * 3)
    xtest2 = xtest.reshape(xtest.shape[0], 256 * 256 * 3)
    print("New shape of xtrain1:", xtrain1.shape)
    print("New shape of xtest2:", xtest2.shape)
else:
    print("Reshape not possible due to element mismatch.")

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

xtrain1 = sc.fit_transform(xtrain1)
xtrain1

xtest2 = sc.fit_transform(xtest2)
xtest2

crops = '/content/drive/MyDrive/agri_data/TrainData/crops'
weeds = '/content/drive/MyDrive/agri_data/TrainData/weeds'

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression(max_iter=1500)

import numpy as np

# Assuming ytrain is a list
ytrain = np.array(ytrain)

# Check the shapes
print("Shape of xtrain1:", xtrain1.shape)
print("Shape of ytrain:", ytrain.shape)

# Ensure they have the same number of samples
if xtrain1.shape[0] != ytrain.shape[0]:
    print("Mismatch in number of samples. Fixing the mismatch...")
    # Handle the mismatch if needed
    if xtrain1.shape[0] > ytrain.shape[0]:
        xtrain1 = xtrain1[:ytrain.shape[0], :]
    else:
        ytrain = ytrain[:xtrain1.shape[0]]

print("Fixed Shape of xtrain1:", xtrain1.shape)
print("Fixed Shape of ytrain:", ytrain.shape)

logistic.fit(xtrain1,ytrain)

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

print(f'Training Score in Logistic Regression = {accuracy_score(ytrain,logistic.predict(xtrain1))}')

print(f'Testing Score in Logistic Regression = {accuracy_score(ytest,logistic.predict(xtest2))}')

cm = confusion_matrix(ytest,logistic.predict(xtest2))

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(cm,annot=True,fmt='.2f',square=True)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()

print('Classification Report in Logistic Regression = ')
print(classification_report(ytest,logistic.predict(xtest2)))

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(splitter='best',criterion='gini')

dt.fit(xtrain1,ytrain)

print(f'Training Score in Decision Tree = {accuracy_score(ytrain,dt.predict(xtrain1))}')

print(f'Training Score in Decision Tree = {accuracy_score(ytest,dt.predict(xtest2))}')

cm = confusion_matrix(ytest,dt.predict(xtest2))

sns.heatmap(cm,annot=True,fmt='.2f',square=True)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()

print('Classification Report in Decision Tree = ')
print(classification_report(ytest,dt.predict(xtest2)))

from sklearn.naive_bayes import GaussianNB

naive = GaussianNB()

naive.fit(xtrain1,ytrain)

print(f'Training Score in Naive Bayes = {accuracy_score(ytrain,naive.predict(xtrain1))}')

print(f'Testing Score in Naive Bayes = {accuracy_score(ytest,naive.predict(xtest2))}')

cm = confusion_matrix(ytest,naive.predict(xtest2))

sns.heatmap(cm,annot=True,fmt='.2f',square=True)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(xtrain1,ytrain)

print(f'Training Score in Random Forest Classifier = {accuracy_score(ytrain,rf.predict(xtrain1))}')

print(f'Testing Score in Random Forest Classifier = {accuracy_score(ytest,rf.predict(xtest2))}')

cm = confusion_matrix(ytest,rf.predict(xtest2))
sns.heatmap(cm,annot=True,fmt='.2f',square=True,cbar=False)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()

import xgboost as xgb

XGB = xgb.XGBClassifier()

XGB.fit(xtrain1,ytrain)

print(f'Training Score in XG Boost Classifier = {accuracy_score(ytrain,XGB.predict(xtrain1))}')

print(f'Testing Score in XG Boost Classifier = {accuracy_score(ytest,XGB.predict(xtest2))}')

cm = confusion_matrix(ytest,XGB.predict(xtest2))
sns.heatmap(cm,annot=True,fmt='.2f',square=True,cmap='winter',cbar=False)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()



from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()

y_probs_1 = logistic.predict_proba(xtest2)
y_probs_2 = dt.predict_proba(xtest2)
y_probs_3 = rf.predict_proba(xtest2)
y_probs_4 = XGB.predict_proba(xtest2)
y_probs_5 = naive.predict_proba(xtest2)

n_classes = len(np.unique(ytest))
n_classes

for i in range(n_classes):
    #y_test_i = (ytest == i).astype(int)
    #print(y_test_i)
    y_test_i = np.array(ytest).astype(int)
    y_score_1 = y_probs_1[:, i]
    y_score_2 = y_probs_2[:, i]
    y_score_3 = y_probs_3[:, i]
    y_score_4 = y_probs_4[:, i]
    y_score_5 = y_probs_5[:, i]
    fpr[1], tpr[1], _ = roc_curve(y_test_i, y_score_1)
    fpr[2], tpr[2], _ = roc_curve(y_test_i, y_score_2)
    fpr[3], tpr[3], _ = roc_curve(y_test_i, y_score_3)
    fpr[4], tpr[4], _ = roc_curve(y_test_i, y_score_4)
    fpr[5], tpr[5], _ = roc_curve(y_test_i, y_score_5)
    roc_auc[1] = auc(fpr[1], tpr[1])
    roc_auc[2] = auc(fpr[2], tpr[2])
    roc_auc[3] = auc(fpr[3], tpr[3])
    roc_auc[4] = auc(fpr[4], tpr[4])
    roc_auc[5] = auc(fpr[5], tpr[5])

plt.figure(figsize=(10,10))
lw = 5
for i in range(1, lw+1):
    plt.plot(fpr[i], tpr[i], lw=lw, label='ROC curve (area = {}) for Model {}'.format(round(roc_auc[i],3), i))
plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', label='minimum area')
plt.xlabel('False Positive Rate',fontsize=18)
plt.ylabel('True Positive Rate',fontsize=18)
plt.title('ROC curve',fontsize=32)
plt.legend(loc="lower right",fontsize=20)
plt.show()

"""Model 4 is Our XGB Classifier with area 90.5"""

cm = confusion_matrix(ytest,XGB.predict(xtest2))
sns.heatmap(cm,annot=True,fmt='.2f',square=True,cmap='winter',cbar=False)
plt.xlabel('Actual Labels')
plt.ylabel('Predicted Labels')
plt.show()

print('Classification Report in XGB Classifier = ')
print(classification_report(ytest,XGB.predict(xtest2)))

"""**Saving the XGB Model**"""

import pickle

pickle.dump(XGB,open('my_crop_weed_model.pkl','wb'))

"""# Testing with Sample Image"""

path = "/content/drive/MyDrive/CropWeed/TrainData/crops/agri_0_1028_0_12.jpg"

import cv2
from google.colab.patches import cv2_imshow

image = cv2.imread("/content/drive/MyDrive/CropWeed/agri_0_1026.jpeg")
#image =cv2.resize(image,(512,512))
cv2_imshow( image)

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Define the paths
train_data_path = '/content/drive/MyDrive/agri_data/TrainData'

# Data augmentation
datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # 20% of data for validation
)

# Load training data with augmentation
train_generator = datagen.flow_from_directory(
    train_data_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training'  # Use for training
)

# Load validation data
validation_generator = datagen.flow_from_directory(
    train_data_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation'  # Use for validation
)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

# Load pre-trained VGG16 model and exclude top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Add custom layers on top of the pre-trained base
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Define the full model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the layers of the pre-trained model
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Set up early stopping
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=15,
    callbacks=[early_stopping]
)

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f"Validation Loss: {loss}")
print(f"Validation Accuracy: {accuracy}")

from tensorflow.keras.preprocessing import image
import numpy as np

def load_and_preprocess_image(img_path):
    # Load image
    img = image.load_img(img_path, target_size=(150, 150))
    # Convert image to array
    img_array = image.img_to_array(img)
    # Expand dimensions to match the input shape (batch_size, height, width, channels)
    img_array = np.expand_dims(img_array, axis=0)
    # Normalize the image
    img_array /= 255.0
    return img_array

def predict_image(model, img_path):
    # Preprocess the image
    img_array = load_and_preprocess_image(img_path)
    # Make prediction
    prediction = model.predict(img_array)
    # Interpret the results
    if prediction[0] > 0.5:
        return "Weed"
    else:
        return "Crop"

# Example usage
img_path = '/content/WhatsApp Image 2024-11-21 at 12.40.26_c63c61f9.jpg'
result = predict_image(model, img_path)
print(f"The image is a: {result}")